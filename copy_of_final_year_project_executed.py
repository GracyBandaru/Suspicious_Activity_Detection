# -*- coding: utf-8 -*-
"""Copy of Final_Year_Project_Executed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-8i9f9H8AVGaWuPHeJ54br7usRybpYje
"""

import zipfile
import os

# Path to the uploaded zip file
zip_path = "/content/DCSASS Dataset.zip"

# Unzip the dataset
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content/dcsass-dataset")

# Verify the unzipped dataset
dataset_path = "/content/dcsass-dataset"
print("Unzipped dataset structure:")
print(os.listdir(dataset_path))

import os

dataset_path = "/content/dcsass-dataset"
print(f"Dataset path: {dataset_path}")
print(f"Contents of dataset folder: {os.listdir(dataset_path)}")

import os

def check_for_video_files(dataset_path):
    video_extensions = (".mp4", ".avi", ".mov")  # Add more extensions if needed
    video_files = []

    for root, dirs, files in os.walk(dataset_path):
        for file in files:
            if file.lower().endswith(video_extensions):
                video_files.append(os.path.join(root, file))

    if not video_files:
        print(f"Error: No video files found in '{dataset_path}'.")
    else:
        print(f"Found {len(video_files)} video files:")
        for video_file in video_files:
            print(video_file)

# Main Execution
if __name__ == "__main__":
    dataset_path = "/content/dcsass-dataset"  # Path to the unzipped dataset
    check_for_video_files(dataset_path)

def load_and_preprocess_data(dataset_path, frame_interval=1, img_size=(64, 64), max_frames=30):
    """
    Load videos, extract frames, and preprocess them for training.
    """
    videos = []
    labels = []

    # Iterate through the dataset
    for root, dirs, files in os.walk(dataset_path):
        print(f"Processing directory: {root}")  # Debug statement
        for file in files:
            if file.endswith((".mp4", ".avi")):  # Check for video files
                print(f"Processing video: {file}")  # Debug statement
                video_path = os.path.join(root, file)
                frames = extract_frames(video_path, frame_interval, img_size)

                # Pad or truncate frames to max_frames
                if len(frames) < max_frames:
                    frames = np.pad(frames, ((0, max_frames - len(frames)), (0, 0), (0, 0)), mode='constant')
                else:
                    frames = frames[:max_frames]

                videos.append(frames)
                labels.append(os.path.basename(root))  # Use folder name as label

    if not videos:
        print("Error: No videos were processed.")  # Debug statement
        return None, None, None, None, None

    videos = np.array(videos)
    labels = np.array(labels)

    # Encode labels to integers
    label_encoder = LabelEncoder()
    labels_encoded = label_encoder.fit_transform(labels)
    labels_one_hot = to_categorical(labels_encoded)

    # Split the dataset
    X_train, X_test, y_train, y_test = train_test_split(videos, labels_one_hot, test_size=0.2, random_state=42)

    return X_train, X_test, y_train, y_test, label_encoder

import os

video_path = "/content/dcsass-dataset/DCSASS Dataset/Abuse/Abuse001_x264.mp4"
if os.path.exists(video_path):
    print(f"The video file '{video_path}' exists.")
else:
    print(f"Error: The video file '{video_path}' does not exist.")

file_size = os.path.getsize(video_path)
print(f"File size: {file_size} bytes")

import os

def explore_dataset(dataset_path):
    print("Exploring dataset structure...")
    video_extensions = (".mp4", ".avi", ".mov")  # Add more extensions if needed
    video_files = []

    for root, dirs, files in os.walk(dataset_path):
        for file in files:
            if file.lower().endswith(video_extensions):
                video_files.append(os.path.join(root, file))

    if not video_files:
        print(f"Error: No video files found in '{dataset_path}'.")
    else:
        print(f"Found {len(video_files)} video files:")
        for video_file in video_files:
            print(video_file)

# Main Execution
if __name__ == "__main__":
    dataset_path = "/content/dcsass-dataset"  # Path to the unzipped dataset
    explore_dataset(dataset_path)

import numpy as np
import cv2
import os
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import Sequence
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Conv2D, MaxPooling2D, Flatten
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping

# Custom Data Generator for Video Frames
class VideoDataGenerator(Sequence):
    def __init__(self, video_files, labels, num_classes, frame_interval=1, img_size=(32, 32), max_frames=20, batch_size=16):
        self.video_files = video_files
        self.labels = labels
        self.num_classes = num_classes
        self.frame_interval = frame_interval
        self.img_size = img_size
        self.max_frames = max_frames
        self.batch_size = batch_size

    def __len__(self):
        return int(np.ceil(len(self.video_files) / self.batch_size))

    def __getitem__(self, index):
        batch_videos = self.video_files[index * self.batch_size:(index + 1) * self.batch_size]
        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]

        X = np.array([self._extract_frames(video) for video in batch_videos])
        y = to_categorical(batch_labels, num_classes=self.num_classes)

        return X, y

    def _extract_frames(self, video_path):
        cap = cv2.VideoCapture(video_path)
        frames = []
        count = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            if count % self.frame_interval == 0:
                frame = cv2.resize(frame, self.img_size)
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                frame = frame / 255.0
                frames.append(frame)
            count += 1
        cap.release()
        if len(frames) < self.max_frames:
            frames = np.pad(frames, ((0, self.max_frames - len(frames)), (0, 0), (0, 0)), mode='constant')
        else:
            frames = frames[:self.max_frames]
        return np.array(frames)

# Define dataset path
dataset_path = "/content/dcsass-dataset/DCSASS Dataset"

# Get list of video files and labels
video_files = []
labels = []
for root, dirs, files in os.walk(dataset_path):
    for file in files:
        if file.endswith((".mp4", ".avi", ".mov")):  # Add more extensions if needed
            video_files.append(os.path.join(root, file))
            # Extract label from the parent folder name (e.g., "Shoplifting")
            label = os.path.basename(os.path.dirname(root))
            labels.append(label)

# Convert labels to integers
label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(labels)
num_classes = len(label_encoder.classes_)
print(f"Number of classes: {num_classes}")

# Split the dataset into training and testing sets
train_video_files, test_video_files, train_labels, test_labels = train_test_split(
    video_files, labels_encoded, test_size=0.2, random_state=42
)

# Create data generators
batch_size = 16  # Reduced batch size
img_size = (32, 32)  # Reduced frame size
max_frames = 20  # Reduced number of frames
train_generator = VideoDataGenerator(train_video_files, train_labels, num_classes, img_size=img_size, max_frames=max_frames, batch_size=batch_size)
test_generator = VideoDataGenerator(test_video_files, test_labels, num_classes, img_size=img_size, max_frames=max_frames, batch_size=batch_size)

# Define the CNN-LSTM model
def build_cnn_lstm_model(input_shape, num_classes):
    model = Sequential()

    # CNN for feature extraction
    model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu'), input_shape=input_shape))  # Reduced filters
    model.add(TimeDistributed(MaxPooling2D((2, 2))))
    model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))  # Reduced filters
    model.add(TimeDistributed(MaxPooling2D((2, 2))))
    model.add(TimeDistributed(Flatten()))

    # LSTM for temporal modeling
    model.add(LSTM(64, return_sequences=False))  # Reduced LSTM units

    # Classification head
    model.add(Dense(32, activation='relu'))  # Reduced dense units
    model.add(Dense(num_classes, activation='softmax'))

    return model

# Initialize TPU strategy (if using TPU)
try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
    print("Running on TPU:", tpu.master())
except ValueError:
    strategy = tf.distribute.get_strategy()
    print("Running on GPU or CPU")

# Build and compile the model within the strategy scope
with strategy.scope():
    input_shape = (max_frames, img_size[0], img_size[1], 1)  # Updated input shape
    model = build_cnn_lstm_model(input_shape, num_classes)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Define Early Stopping callback
early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=3,          # Wait for 3 epochs without improvement
    restore_best_weights=True  # Restore the best model weights
)

# Train the model with Early Stopping
epochs = 10  # Maximum number of epochs
history = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=test_generator,
    verbose=1,
    callbacks=[early_stopping]  # Add Early Stopping callback
)

# Evaluate the model
loss, accuracy = model.evaluate(test_generator)
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")

# Save the model
model.save("suspicious_activity_detection_model.h5")

# Make predictions
def predict_video(model, video_path, label_encoder, frame_interval=1, img_size=(32, 32), max_frames=20):
    """
    Predict the class of a new video.
    """
    # Extract frames from the video
    cap = cv2.VideoCapture(video_path)
    frames = []
    count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if count % frame_interval == 0:
            frame = cv2.resize(frame, img_size)
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            frame = frame / 255.0
            frames.append(frame)
        count += 1
    cap.release()
    if len(frames) < max_frames:
        frames = np.pad(frames, ((0, max_frames - len(frames)), (0, 0), (0, 0)), mode='constant')
    else:
        frames = frames[:max_frames]
    frames = np.array(frames)

    # Add batch dimension
    frames = np.expand_dims(frames, axis=0)

    # Predict the class
    prediction = model.predict(frames)
    predicted_class = np.argmax(prediction, axis=1)
    predicted_label = label_encoder.inverse_transform(predicted_class)

    return predicted_label[0]

# Example: Predict on a new video
sample_video_path = "/content/dcsass-dataset/DCSASS Dataset/Abuse/Abuse001_x264.mp4/Abuse001_x264_0.mp4"
predicted_label = predict_video(model, sample_video_path, label_encoder)
print(f"Predicted Label: {predicted_label}")

# Example: Predict on a new video
sample_video_path = "/content/dcsass-dataset/DCSASS Dataset/Shooting/Shooting002_x264.mp4/Shooting002_x264_0.mp4"
predicted_label = predict_video(model, sample_video_path, label_encoder)
print(f"Predicted Label: {predicted_label}")

from google.colab import files

# Save the model
model.save("suspicious_activity_detection_model.h5")

# Download the .h5 file
files.download("suspicious_activity_detection_model.h5")

import matplotlib.pyplot as plt

def plot_training_history(history):
    """
    Plot training and validation accuracy and loss graphs.

    Args:
        history: History object returned by model.fit().
    """
    # Plot training & validation accuracy values
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(loc='upper left')

    # Plot training & validation loss values
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(loc='upper left')

    plt.show()

# Example usage
plot_training_history(history)

print(test_generator.labels.shape)

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Get true and predicted labels
y_true = test_generator.labels  # Shape: (3328,)

# Get predicted labels
y_pred = model.predict(test_generator)
y_pred = np.argmax(y_pred, axis=1)  # Convert predictions to integers

# Class names (replace with your actual class names)
class_names = label_encoder.classes_

# Plot confusion matrix
def plot_confusion_matrix(y_true, y_pred, class_names):
    """
    Plot a confusion matrix.

    Args:
        y_true: True labels.
        y_pred: Predicted labels.
        class_names: List of class names.
    """
    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

# Print classification report
def print_classification_report(y_true, y_pred, class_names):
    """
    Print a classification report.

    Args:
        y_true: True labels.
        y_pred: Predicted labels.
        class_names: List of class names.
    """
    report = classification_report(y_true, y_pred, target_names=class_names)
    print(report)

# Plot confusion matrix
plot_confusion_matrix(y_true, y_pred, class_names)

# Print classification report
print_classification_report(y_true, y_pred, class_names)

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize

def plot_roc_curve(y_true, y_pred_prob, class_names):
    """
    Plot ROC curve for multi-class classification.

    Args:
        y_true: True labels.
        y_pred_prob: Predicted probabilities for each class.
        class_names: List of class names.
    """
    # Binarize the true labels
    y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))

    # Compute ROC curve and ROC area for each class
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(len(class_names)):
        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Plot ROC curve
    plt.figure(figsize=(8, 6))
    for i in range(len(class_names)):
        plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend(loc='lower right')
    plt.show()

# Example usage
# Get predicted probabilities
y_pred_prob = model.predict(test_generator)

# Plot ROC curve
plot_roc_curve(y_true, y_pred_prob, class_names)

from sklearn.metrics import precision_recall_curve, average_precision_score

def plot_precision_recall_curve(y_true, y_pred_prob, class_names):
    """
    Plot precision-recall curve for multi-class classification.

    Args:
        y_true: True labels.
        y_pred_prob: Predicted probabilities for each class.
        class_names: List of class names.
    """
    # Binarize the true labels
    y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))

    # Compute precision-recall curve and average precision for each class
    precision = dict()
    recall = dict()
    average_precision = dict()
    for i in range(len(class_names)):
        precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])
        average_precision[i] = average_precision_score(y_true_bin[:, i], y_pred_prob[:, i])

    # Plot precision-recall curve
    plt.figure(figsize=(8, 6))
    for i in range(len(class_names)):
        plt.plot(recall[i], precision[i], label=f'{class_names[i]} (AP = {average_precision[i]:.2f})')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc='lower left')
    plt.show()

# Example usage
plot_precision_recall_curve(y_true, y_pred_prob, class_names)

import pandas as pd

def plot_class_distribution(y_true, class_names):
    """
    Plot the distribution of classes.

    Args:
        y_true: True labels.
        class_names: List of class names.
    """
    # Count the number of samples for each class
    class_counts = pd.Series(y_true).value_counts().sort_index()

    # Plot class distribution
    plt.figure(figsize=(8, 6))
    plt.bar(class_names, class_counts)
    plt.title('Class Distribution')
    plt.xlabel('Class')
    plt.ylabel('Number of Samples')
    plt.show()

# Example usage
plot_class_distribution(y_true, class_names)

# Step 1: Plot training and validation accuracy/loss graphs
plot_training_history(history)

# Step 2: Plot confusion matrix
plot_confusion_matrix(y_true, y_pred, class_names)

# Step 3: Plot ROC curve
plot_roc_curve(y_true, y_pred_prob, class_names)

# Step 4: Plot precision-recall curve
plot_precision_recall_curve(y_true, y_pred_prob, class_names)

# Step 5: Plot class distribution
plot_class_distribution(y_true, class_names)

plt.savefig('confusion_matrix.png')
plt.savefig('roc_curve.png')

with open('classification_report.txt', 'w') as f:
    f.write(classification_report(y_true, y_pred, target_names=class_names))

!apt-get install git

!git clone https://github.com/GracyBandaru/Suspicious_Activity_Detection.git